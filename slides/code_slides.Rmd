---
title: "Meta-analysis in Comparative Physiology: A brief introduction to effect sizes and meta-analytic modelling"
author: Daniel W.A Noble, Nicholis Wu, Essie Rodgers, Patrice Pottier
output: powerpoint_presentation
date: '`r Sys.Date()`'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Load packages
pacman::p_load(metafor, flextable, tidyverse, orchaRd, pander, mathjaxr, equatags, vembedr, magick)
```

## Slide with Bullets {.secondslide}

- Bullet 1
- Bullet 2
- Bullet 3

$$
y_{i} = x^2
$$

> - Eat eggs
> - Drink coffee

## Slide with R Output {.thirdslide}

```{r cars, echo = TRUE, tidy=TRUE}
# LDH activity in 8 C treatment
 trt_8C <- rnorm(10, 0.40, 0.5)

# LDH activity in 26 C treatment
trt_26C <- rnorm(10, 0.60, 0.20)

# What's the difference, i.e., effect size, between treatments?
mean(trt_26C - trt_8C)
t.test(trt_26C, trt_8C)
```


## Do 1000s of experiments

```{r sim, echo = TRUE, tidy=TRUE}

experiment <- function(times){
  
  dat <- data.frame(matrix(nrow = times, ncol = 2))
  
  for(i in 1:times){
  # LDH activity in 8 C treatment
   trt_8C <- rnorm(10, 0.40, 0.5)
  
  # LDH activity in 26 C treatment
  trt_26C <- rnorm(10, 0.60, 0.20)
  
  # What's the difference, i.e., effect size, between treatments?
  dat[i,1] <- mean(trt_26C - trt_8C)
  dat[i,2] <- t.test(trt_26C, trt_8C)$p.value
    
  }
  names(dat) <- c("effect", "p")
  return(dat)
}

expts <- experiment(10000)
```

## Figure

```{r simfig, echo = FALSE, tidy=TRUE}
par(mfrow = c(1,2))
hist(expts$effect, xlab = "Effect size", main = "")
hist(expts$p, xlab = "p-value", main = "")
```

## errors

$$
SE = SD / \sqrt{N}
$$


```{r simfig2, echo = TRUE, tidy=TRUE}
sd(expts$effect)

```



## se

```{r simfig3, echo = TRUE, eval = FALSE, tidy=TRUE}
  means <- c()

   for (i in 1:1000000){
      mass <- rnorm(n = 18, mean = 10.8, sd = 0.988)
      means <- c(means, mean(mass))
    }

   # The mean of the means
   mean(means)
   # The standard deviation of the means or standard error
   sd(means)
```

## Our analytical calculaton

```{r se, echo = TRUE, eval = FALSE, tidy=TRUE}
se <- sd(mass) / sqrt(length(mass))
se
```
## Plots
```{r simfig3plot, echo = TRUE, eval = FALSE, tidy=TRUE}
   ggplot() + geom_histogram(aes(x = means))
```


## Zr

```{r Zr,  echo = TRUE}
zr_data <- read.csv("https://raw.githubusercontent.com/daniel1noble/meta-workshop/gh-pages/data/ind_disp_raw_data.csv") %>%
  dplyr::select(study_ID, taxa, species, trait, response, response_unit, disp_trait, disp_unit, corr_coeff, sample_size) %>% # remove irrelevant columns for this tutorial
  dplyr::top_n(10) # select first 10 effect sizes to illustrate escalc function
```

## Effect calculation
```{r Zrescalc,  echo = TRUE}
# Calculate Fisher's r-to-z transformed correlation coefficient (ZCOR) as yi = effect size and vi = sampling variances, where ri = raw correlation coefficients, and ni = sample size.
zr_data <- metafor::escalc(measure = "ZCOR", ri = corr_coeff, ni = sample_size, data = zr_data, var.names=c("Zr","v_Zr"))

zr_data
```

## Back transofrmation

```{r Zrescalcbackcalc, echo = TRUE}
# We can easily convert back to r as follows
zr_data$r <- tanh(zr_data$Zr)

zr_data %>% select(corr_coeff, r)
```


## Hedges

```{r lnRR, echo = TRUE}
contrast_data <- read.csv("https://raw.githubusercontent.com/daniel1noble/meta-workshop/gh-pages/data/pop_disp_raw_data.csv") %>%
  dplyr::select(study_ID, taxa, species, trait, response, response_unit, mean_core, sd_core, n_core, mean_front, sd_front, n_front) %>% # remove irrelevant columns for this tutorial
  dplyr::top_n(10) # select first 10 effect sizes to illustrate escalc function
```

## Hedgesg
```{r hedges, echo = TRUE}
# Calculate Hedges' g as g = effect size and v_g = sampling variances, where m1i = mean of edge population, n1i = sample size of edge population, sd1i = standard deviation of edge population, m2i = mean of core population, n2i = sample size of core population, sd2i = standard deviation of core population.
contrast_data <- metafor::escalc(measure = "SMD", 
                              m1i = mean_front, n1i = n_front, sd1i = sd_front,
                              m2i = mean_core, n2i = n_core, sd2i = sd_core, 
                              data = contrast_data, var.names=c("g","v_g"))
contrast_data %>% select(study_ID, mean_core, sd_core, n_core, mean_front, sd_front, n_front, g, v_g)
```


## lnRR
```{r lnRREffects, echo = TRUE}
# Calculate log response ratio, lnRR = effect size and v_lnRR = sampling variances, where m1i = mean of edge population, n1i = sample size of edge population, sd1i = standard deviation of edge population, m2i = mean of core population, n2i = sample size of core population, sd2i = standard deviation of core population.
contrast_data <- metafor::escalc(measure = "ROM", 
                              m1i = mean_front, n1i = n_front, sd1i = sd_front,
                              m2i = mean_core, n2i = n_core, sd2i = sd_core, 
                              data = contrast_data, var.names=c("lnRR","v_lnRR"))
contrast_data %>% select(study_ID, mean_core, sd_core, n_core, mean_front, sd_front, n_front, lnRR, v_lnRR)
```

## COnverting back to understand lnRR

```{r ConvertLnRR, echo = TRUE}
### Let's back calculate effects to make sure we understand why they are interpreted as percentage differences

# Make sure we understand how it's calculated
with(contrast_data, log(mean_front[1] / mean_core[1]))

# Alternatively....
with(contrast_data, log(mean_front[1]) - log(mean_core[1]))

# Now lets back-transform to odds. 
with(contrast_data, exp(log(mean_front[1]) - log(mean_core[1])))

# Interpretation: What this tells us is that the numerator is 1.15 times the denominator, or, that the marginal (front) mean is 15% larger compared to the core mean. We can see that this is true as follows:
with(contrast_data, exp(log(mean_front[1]) - log(mean_core[1])) * mean_core[1])

# This value should now match the marginal mean value, which it does
with(contrast_data, mean_front[1])
```


## Latency

$$
ln \bar{X} = log(\bar{X}) - log \sqrt{ \left ( 1 + \frac{SD^2}{\bar{X}^2}\right )}
$$

$$
lnSD = \sqrt{ log \left (   1 + \frac{SD^2}{\bar{X}^2} \right )}
$$

## Proportions

$$
\bar{X_{p}} = log \left ( \frac{p}{ 1 - p } \right ) 
$$

$$
SD_{p} = \sqrt{SD^2 \left ( \frac{1}{p} \right ) + \left ( \frac{p}{ 1 - p^2} \right )}
$$

## Arcsine transformation
$$
\bar{X_{t}} = arcsine(\sqrt{\bar{{X}}})
$$
$$
SD_{t} = \sqrt{\frac{SD^2}{4\bar{X}\left ( 1- \bar{X}\right ) }}
$$
## Geary test - Counts

$$
\frac{\bar{X}}{SD} \left ( \frac{4N^{3/2}}{1 + 4N} \right ) \geq 3
$$

## Q10

$$
\begin{equation} 
  lnRR_{Q_{10}} = ln\left( \frac{R_{2}}{R_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }
(\#eq:lnq10)
\end{equation} 
$$ 

$$
\begin{equation} 
  s^2_{lnRR_{Q_{10}}} = \left( \frac{SD_{2}^2}{R^2_{2}N_{2}} + \frac{SD_{1}^2}{R^2_{1}N_{1}} \right){ \left(\ \frac{10^{\circ}C}{T_{2}-T_{1}} \right) }^2
  (\#eq:Vlnq10)
\end{equation} 
$$
