---
title: "Multi-level Meta-Regression"
author: Daniel W.A. Noble 
date: '`r Sys.Date()`'
bibliography: ./bib/refs.bib
csl: ./bib/the-journal-of-experimental-biology.csl
output:
  bookdown::html_document2:
    css: style.css
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, tidy = TRUE)
options(digits=3)
```

```{r klippy, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
#install.packages("devtools")
remotes::install_github("rlesur/klippy")
klippy::klippy(tooltip_message = 'Click to Copy Code', tooltip_success = 'Done', position = 'right', color = "red")

# Load packages
pacman::p_load(metafor, flextable, tidyverse, orchaRd, pander, mathjaxr, equatags, vembedr, magick)

```

## Introduction to Multi-level Meta-Regression

Meta-analysis often reveals substantial heterogeneity among effect estimates included in the analysis [@Senior2016]. While many meta-analysts are interested in 'overall mean effects' we need to couch these effects in context by reporting on their variability and work hard to understand what factor drive effect variability and why [@Noble2022; @Lag2010]. For meta-analyses in comparative physiology, explaining variation in effects should probably be the main goal of every analysis. Sampling variance often explains only a little amount of the total heterogeneity, so it's important that we think hard, *a priori*, about what factors are likely to explain effect size variation. 

As already indicated, some variation in effects could be explained by [nuisance heterogeneity](https://daniel1noble.github.io/meta-workshop/nuis-het), which may or may not be of main interest. Other sources of variability could be methodological or analytical [@Noble2022]. Do different chemicals that result in oxidative stress induce stronger or weaker responses? However, possibly more importantly, biological variables are our main interest. Why do some species exhibit stronger responses than others? Do ectotherms exhibit stronger responsees than endotherms? 

Exploring population-level / average changes in effect size magnitude (and direction) as a function of 'moderators' (what are typically called predictors or fixed effects in other literature) is a critical aspects of meta-analysis in ecology and evolution. The models used to test how average effects change as some function of a moderator is called meta-regression. 



## Extending our Multi-level Meta-analytic Model


$$
y_{i} = \mu + s_{j[i]} + spp_{k[i]} + e_{i} + m_{i} \\
m_{i} \sim N(0, v_{i}) \\
s_{j} \sim N(0, \tau^2) \\
s_{k} \sim N(0, \sigma_{k}^2) \\
e_{i} \sim N(0, \sigma_{e}^2)
$$

## Fitting a Multi-level Meta-Regression Model

![](./figs/pottier.png)

To demonstrate how to fit a multilevel meta-analytic model similar to the one discussed above we'll turn to a [familiar example](https://daniel1noble.github.io/meta-workshop/nuis-het) by @Pottier2021, who used the acclimation response ratio (ARR) to analyse thermal acclimation responses on $CT_{max}$ and how this differs between the sexes. We'll keep it simple for the moment and focus exclusively on a single sex. 

### Download Data and Functions for $ARR$

We'll download the raw data from the paper again. We'll also need to load the `metafor` package to fit our models and the tidyverse package for processing the data.

```{r}
# install.packages("pacman") ; uncomment this line if you haven't already installed 'pacman'
pacman::p_load(metafor, tidyverse)

asr_dat <- read.csv("https://osf.io/qn2af/download")
```

We'll also need our function for calculating ARR and its sampling variance because these don't exist in any current packages. 

```{r ARRfunc}
#' @title arr
#' @description Calculates the acclimation response ratio (ARR).  
#' @param t2_l  Lowest of the two treatment temperatures
#' @param t1_h  Highest of the two treatment temperatures
#' @param x1_h  Mean trait value at high temperature
#' @param x2_l  Mean trait value at low temperature
#' @param sd1_h Standard deviation of mean trait value at high temperature
#' @param sd2_l Standard deviation of mean trait value at low temperature
#' @param n1_h  Sample size at high temperature
#' @param n2_l  Sample size at low temperature

arr <- function(x1_h, x2_l, sd1_h, sd2_l, n1_h, n2_l, t1_h, t2_l){
        ARR <- (x1_h - x2_l)/(t1_h - t2_l)
      V_ARR <- ((1/(t1_h - t2_l))^2*(sd2_l^2/n2_l + sd1_h^2/n1_h))
return(data.frame(ARR, V_ARR))
}
```


### Calculating $ARR$ and It's Sampling Variance
Using the `arr` function above we can now calculate the acclimation response ratio (ARR). Given @Pottier2021 were interested in comparing the sexes, they calculated the ARR difference between males and females. To simplify here, we'll just focus on estimating the ARR for a single sex, females. As such, we'll calculate our ARR effect size and sampling variance and then sub-set out the data on females.

```{r, tidy=TRUE}
# Calculate the effect sizes
asr_dat<-asr_dat %>% 
              mutate(ARR= arr(x1_h = mean_high, x2_l = mean_low, t1_h = acc_temp_high, t2_l = acc_temp_low, 
                              sd1_h = sd_high, sd2_l = sd_low, n1_h = n_high_adj, n2_l = n_low_adj)[,1], 
                     V_ARR = arr(x1_h =  mean_high, x2_l = mean_low, t1_h = acc_temp_high, t2_l = acc_temp_low, 
                           sd1_h = sd_high, sd2_l = sd_low, n1_h = n_high_adj, n2_l = n_low_adj)[,2]) %>% 
                filter(sex == "female")
```

### Fitting a Multilevel Meta-analytic Model in `metafor`

Our data is now ready for analysis! We will use the `rma.mv` function in `metafor` to fit our first multilevel meta-analysis model. The model takes the ARR as a response variable (`yi`) and accounts for it's sampling variance (`V` = V_ARR). We are also going to estimate a random effect variance for species, between study and within-study grouping variables to control for non-independence and understand sources driving effect size variability. These are all denoted in the `random` argument of `metafor` which takes a list of all the random effects. 

You will notice two additional arguments being specified: 

* The first, `dfs`, which calculates the degrees of freedom for the inferential tests in the model. `dfs = "contain"` will calculate the degrees of freedom based on the lowest clustering level minus 1 (in this case study). Simulations have shown that this is a more robust measure to protect against type I errors [@Nakagawa2021]. 

* The second argument, `test` specifies the test statistic used. `metafor` defaults to z values based on the standard normal distribution, however, simulations have shown [@Pappalardo2021] and it has been recommended [@Rosenberg2013b], that the t-distribution be used because samples sizes are often small and the true variance of the test is being estimated. 

```{r, class.source='klippy'}

# Multi-level meta-analytic model
MLMA <- metafor::rma.mv(yi= ARR~ 1, V = V_ARR, 
                   method="REML",
                   random=list(~1|species_ID,
                               ~1|authors,
                               ~1|es_ID), 
                   dfs = "contain",
                   test="t",
                   data=asr_dat)
print(MLMA)

```

**Interpretation**: We can see from above that the model estimates an **overall meta-analytic mean as `r MLMA$b` with a 95% confidence interval of `r MLMA$ci.lb` to `r MLMA$ci.ub`**. **In other words, for each degree variation in acclimation temperature female heat tolerance changes by an average of `r MLMA$b`$^{\circ}$C**. 

We can also see that there's a significant amount of heterogeneity among our effect size estimates with our *Q*-test being significant. Some of this heterogeneity seems to be driven by variation among studies, within studies and among species as judged by the variance components of the model. We'll probe how to dissect and discuss this heterogeneity in later tutorials. 


## Niky moved phylogenetic MLMA here
### Run phylogenetically corrected, multi-level meta-regression

We will first extract the raw data, calculate Zr and sampling variance, and reconstruct the phylogeny from the [Phylogenetic Meta-analysis tutorial](https://daniel1noble.github.io/meta-workshop/phylo). Note, we have now included additional moderators `Zr_sei` and `year_centre` in the raw data. The magnitude of the overall effect can be exaggerated because statistically non-significant effect sizes are less likely to be published, especially when they are based on small sample sizes (here as standard error `Zr_sei`; [@Nakagawa2021b](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13724)). Time-lag bias occurs when larger or statistically significant effects are published more quickly than smaller or non-statistically significant effects, and can manifest as a decline in the magnitude of the overall effect over time (i.e. a decline effect; [@Clements2022](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001511)). To test this, we standardise the publication year as `year_centre` (i.e. set the mean value of year as 0).

```{r raw data}
pacman::p_load(rotl, ape)

zr_data <- read.csv("https://raw.githubusercontent.com/daniel1noble/meta-workshop/gh-pages/data/ind_disp_raw_data.csv") %>%
  dplyr::select(-dispersal_def) %>% # remove irrelevant columns
  tibble::rowid_to_column("es_ID") %>% # add effect size ID
  dplyr::mutate(Zr_sei      = 1 / sqrt(sample_size - 3), # Standard error (SE)
                year_centre = year - mean(year),  # mean-centring year of publication
                species_OTL = stringr::str_replace_all(species_OTL, "_", " ")) # remove underscore for some species with missing underscore. Some inconsistency when curating the database.

# Calculate Zr and sampling variance
zr_data <- metafor::escalc(measure = "ZCOR", ri = corr_coeff, ni = sample_size, data = zr_data, var.names = c("Zr", "V_Zr"))

# Create species list based on OTL names and match with OTL database
species <- sort(unique(as.character(zr_data$species_OTL))) # generate list of species (as character format)
taxa    <- rotl::tnrs_match_names(names = species) # match taxonomic names to the OTL

# Retrieving phylogenetic relationships among taxa in the form of a trimmed sub-tree
tree <- rotl::tol_induced_subtree(ott_ids = ott_id(taxa), label_format = "name")

set.seed(1) 
tree <- ape::compute.brlen(tree, method = "Grafen", power = 1) # compute branch lengths
tree <- ape::multi2di(tree, random = TRUE) # use a randomization approach to deal with polytomies

# Create correlation matrix for analysis
phylo_cor <- vcv(tree, cor = T)
```

From the original study aim, the first thing we were interested in is the relationship of physiology with activity, exploration and dispersal (Zr). The following code runs a phylogeneticlly corrected, multi-level meta-analysis via the `rma.mv` function. We have a “~ -1” in the `mod` argument because we are interested in the effect size of activity, exploration and dispersal, not the overall model. If you are interested in the overall model, run the code with ” ~ 1” instead. `disp_trait` (activity, exploration, or dispersal) was our main interest, with the moderator `Zr_sei` (effect size standard error) and `year_centre` (mean centering of year) to test for time-lag and publication bias [@Nakagawa2021b].

Building upon the multi-level meta-analytic model from the [Multi-level Meta-analysis](https://daniel1noble.github.io/meta-workshop/multi-level#Building_more_Complex_Multilevel_Meta-analytic_Models) section, we also included random effects (`random` argument) to account for non-independence such as `es_ID` (effect size identity), `study_ID`(unique study identity), `species`(unique species identity), `species_OTL`(species relatedness). The `R` argument allows the correlation matrix (here, `phylo_cor`) to be incorporated to the model which corresponds to the components specified in the `random` argument `~1 | species_OTL`.

Note: remember to add underscore to the species OTL because the tree tip names have underscores.

```{r analysis}
overall_model <- metafor::rma.mv(yi = Zr, V = V_Zr, 
                                        mod    = ~ -1 + disp_trait + Zr_sei + year_centre, 
                                        random = list(~1 | study_ID, ~1 | es_ID, ~1 | species, ~1 | species_OTL),
                                        R      = list(species_OTL = phylo_cor),
                                        method = "REML", test = "t",
                                        data   = zr_data %>%
                                   dplyr::mutate(species_OTL = stringr::str_replace_all(species_OTL, " ", "_")))
summary(overall_model)
```

**Interpretation**: We can see from above that the model estimates **a positive relationship** between physiology and activity with **an overall mean of `r overall_model$b[1,]` with a 95% confidence interval (95% CI) of `r overall_model$ci.lb[1]` to `r overall_model$ci.ub[1]`**. Exploration and dispersal was also, on average, positively associated with physiology, but exploration had higher level of uncertainty (Exploration = `r overall_model$b[3,]` [95% CI `r overall_model$ci.lb[3]`, `r overall_model$ci.ub[3]`], Dispersal = `r overall_model$b[2,]`, [95% CI `r overall_model$ci.lb[2]`, `r overall_model$ci.ub[2]`]). 

There was no evidence of the influence of small sample size bias (`r overall_model$b[4,]` [95% CI `r overall_model$ci.lb[4]`, `r overall_model$ci.ub[4]`]) and time-lag (`r overall_model$b[5,]` [95% CI `r overall_model$ci.lb[5]`, `r overall_model$ci.ub[5]`]). Heterogeneity remained high in this analysis based on the Q-test. 

## References

<div id="refs"></div>

<br>

## Session Information

```{r sessioninfo, echo = FALSE}
pander(sessionInfo(), locale = FALSE)
```

## [Back to Table of Contents](https://daniel1noble.github.io/meta-workshop/) {.hide}

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
